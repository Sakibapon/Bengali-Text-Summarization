{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, GRU\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.initializers import Constant\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame()\n",
    "df_test=pd.DataFrame()\n",
    "df=pd.read_csv(\"dataset_total.csv\", encoding=\"utf-8\")\n",
    "df_test=pd.read_csv(\"test_set.csv\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sentence=df[\"sentence\"].values.tolist()\n",
    "y_train= df.loc[:1999, \"label\"].values\n",
    "y_test= df.loc[2000:, \"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"stopword.txt\", 'r', encoding='utf-8-sig') as f:\n",
    "    stop_words= f.read()\n",
    "    stop_words=stop_words.replace(\" \", \"\")\n",
    "    stop_words=stop_words.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_sen=[]\n",
    "for sentence in all_sentence:\n",
    "    sentence= re.sub('[১২৩৪৫৬৭৮৯০]', '', sentence)\n",
    "    sentence= re.sub(' +', ' ', sentence)\n",
    "    sentence=sentence.split()\n",
    "    sentence=[w for w in sentence if not w in stop_words]\n",
    "    processed_sen.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x=df_test[\"documents\"].values.tolist()\n",
    "test_y=df_test[\"summaries\"].values.tolist()\n",
    "test_x_doc=[]\n",
    "for document in test_x:\n",
    "    document=document.split(\"।\")\n",
    "    test_x_doc.append(document)\n",
    "    \n",
    "processed_test_x=[]\n",
    "for doc in test_x_doc:\n",
    "    processed_test_doc=[]\n",
    "    for sentence in doc:\n",
    "        sentence= re.sub('[১২৩৪৫৬৭৮৯০]', '', sentence)\n",
    "        sentence= re.sub(' +', ' ', sentence)\n",
    "        sentence=sentence.split()\n",
    "        sentence=[w for w in sentence if not w in stop_words]\n",
    "        processed_test_doc.append(sentence)\n",
    "    processed_test_x.append(processed_test_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_obj = Tokenizer()\n",
    "tokenizer_obj.fit_on_texts(processed_sen)\n",
    "max_length= max([len(s) for s in processed_sen])\n",
    "vocab_size = len(tokenizer_obj.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=processed_sen[:2000]\n",
    "x_test=processed_sen[2000:]\n",
    "\n",
    "x_tranin_tokens= tokenizer_obj.texts_to_sequences(x_train)\n",
    "x_test_tokens= tokenizer_obj.texts_to_sequences(x_test)\n",
    "\n",
    "x_train_pad=pad_sequences(x_tranin_tokens, maxlen=max_length, padding=\"post\")\n",
    "x_test_pad=pad_sequences(x_test_tokens, maxlen=max_length, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##using GRU\n",
    "E_D=60\n",
    "model_gru = Sequential()\n",
    "model_gru.add(Embedding(vocab_size, E_D, input_length=max_length))\n",
    "model_gru.add(GRU(units=32, dropout=0.2, recurrent_dropout=0.2))\n",
    "model_gru.add(Dense(64, activation='relu'))\n",
    "model_gru.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model_gru.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model_gru.summary()\n",
    "model_gru.fit(x_train_pad, y_train, batch_size=32, epochs=25, validation_data=(x_test_pad, y_test), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##using LSTM\n",
    "from keras.layers import Dense, Dropout\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, output_dim=256))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_pad, y_train, batch_size=16, epochs=25)\n",
    "score = model.evaluate(x_test_pad, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_token=  tokenizer_obj.texts_to_sequences(processed_test_x[1])\n",
    "test_pad=pad_sequences(test_token, maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "out=model.predict(test_pad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
